{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECOMMENDER SYSTEM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pymongo import MongoClient\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm \n",
    "\n",
    "client = MongoClient(\"MONGODB-URL\")\n",
    "db = client[\"DATABASE-NAME\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_data():\n",
    "    ratings_data = pd.DataFrame(list(db[\"ratings\"].find()))\n",
    "    songs_data = pd.DataFrame(list(db[\"songs\"].find()))\n",
    "    activity_data = pd.DataFrame(list(db[\"user_activity\"].find()))\n",
    "    user_data = pd.DataFrame(list(db[\"users\"].find()))\n",
    "    user_song_ratings = pd.pivot_table(ratings_data, values='rating', index='user_id', columns='track_id').fillna(0)\n",
    "    user_ids, track_ids = np.nonzero(user_song_ratings)\n",
    "    ratings = [user_song_ratings.iloc[user, track] for user, track in zip(user_ids, track_ids)]\n",
    "    merged_data = ratings_data.merge(activity_data, on=\"user_id\", how=\"left\").merge(user_data, on=\"user_id\", how=\"left\")\n",
    "    return user_ids, track_ids, np.array(ratings), songs_data, merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFWithDemographics(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors, n_genres, n_languages):\n",
    "        super(NCFWithDemographics, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(n_users, n_factors)\n",
    "        self.item_embedding = nn.Embedding(n_items, n_factors)\n",
    "        \n",
    "        self.genre_embedding = nn.Embedding(n_genres, n_factors)\n",
    "        self.language_embedding = nn.Embedding(n_languages, n_factors)\n",
    "        self.age_embedding = nn.Embedding(100, n_factors)\n",
    "        self.gender_embedding = nn.Embedding(2, n_factors)\n",
    "        \n",
    "        self.fc1 = nn.Linear(n_factors * 6, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, user_id, item_id, genre_id, language_id, age, gender):\n",
    "        user_vec = self.user_embedding(user_id)\n",
    "        item_vec = self.item_embedding(item_id)\n",
    "        genre_vec = self.genre_embedding(genre_id)\n",
    "        language_vec = self.language_embedding(language_id)\n",
    "        age_vec = self.age_embedding(age)\n",
    "        gender_vec = self.gender_embedding(gender)\n",
    "        \n",
    "        x = torch.cat([user_vec, item_vec, genre_vec, language_vec, age_vec, gender_vec], dim=1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return torch.sigmoid(self.output(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(Dataset):\n",
    "    def __init__(self, user_ids, track_ids, ratings, genres, languages, ages, genders):\n",
    "        self.user_ids = torch.LongTensor(user_ids)\n",
    "        self.track_ids = torch.LongTensor(track_ids)\n",
    "        self.ratings = torch.FloatTensor(ratings)\n",
    "        self.genres = torch.LongTensor(genres)\n",
    "        self.languages = torch.LongTensor(languages)\n",
    "        self.ages = torch.LongTensor(ages)\n",
    "        self.genders = torch.LongTensor(genders)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.track_ids[idx], self.ratings[idx], self.genres[idx], self.languages[idx], self.ages[idx], self.genders[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_encoders(model, genre_encoder, language_encoder):\n",
    "    torch.save(model.state_dict(), 'Files\\ncf_model.pth')\n",
    "    with open('Files\\genre_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(genre_encoder, f)\n",
    "    with open('Files\\language_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(language_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving: 253.22670197486877\n",
      "UserRatingMatrix: 292.9425401687622\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "user_ids, track_ids, ratings, songs_data, merged_data = retrieve_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(user_ids, track_ids, ratings, songs_data, merged_data):\n",
    "    genre_encoder = LabelEncoder()\n",
    "    language_encoder = LabelEncoder()\n",
    "\n",
    "    merged_data['genre_id'] = genre_encoder.fit_transform(merged_data['preferred_genre'])\n",
    "    merged_data['language_id'] = language_encoder.fit_transform(merged_data['preferred_language'])\n",
    "    \n",
    "    ages = merged_data['user_age'].values\n",
    "    genders = merged_data['user_gender'].values\n",
    "    genres = merged_data['genre_id'].values\n",
    "    languages = merged_data['language_id'].values\n",
    "\n",
    "    train_dataset = RatingDataset(user_ids, track_ids, ratings, genres, languages, ages, genders)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "    n_users, n_items = len(set(user_ids)), len(set(track_ids))\n",
    "    n_genres = len(genre_encoder.classes_)\n",
    "    n_languages = len(language_encoder.classes_)\n",
    "\n",
    "    model = NCFWithDemographics(n_users, n_items, 20, n_genres, n_languages)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    epochs = 10\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        with tqdm(train_loader, total=len(train_loader), desc=f'Epoch {epoch+1}/{epochs}', unit='batch') as pbar:\n",
    "            for user_id, item_id, rating, genre_id, language_id, age, gender in pbar:\n",
    "                optimizer.zero_grad()\n",
    "                prediction = model(user_id, item_id, genre_id, language_id, age, gender)\n",
    "                loss = criterion(prediction.squeeze(), rating)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                pbar.set_postfix(loss=total_loss/len(train_loader))\n",
    "        \n",
    "        epoch_end_time = time.time()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed in {epoch_end_time - epoch_start_time:.2f} seconds, Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    save_model_and_encoders(model, genre_encoder, language_encoder)\n",
    "    return model, genre_encoder, language_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "EncoderData: 0.4942340850830078 seconds\n",
      "TrainDataset: 0.00517582893371582 seconds\n",
      "TrainLoader: 0.0 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 9618/9618 [06:11<00:00, 25.87batch/s, loss=0.000327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 completed in 371.80 seconds, Loss: 0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 9618/9618 [06:04<00:00, 26.38batch/s, loss=6.68e-11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 completed in 364.58 seconds, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 9618/9618 [06:08<00:00, 26.07batch/s, loss=2.33e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 completed in 368.90 seconds, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 9618/9618 [06:12<00:00, 25.83batch/s, loss=4.6e-13] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 completed in 372.42 seconds, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 9618/9618 [06:14<00:00, 25.69batch/s, loss=2.24e-13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 completed in 374.35 seconds, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 9618/9618 [06:13<00:00, 25.76batch/s, loss=1.48e-13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 completed in 373.40 seconds, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 9618/9618 [06:19<00:00, 25.35batch/s, loss=1.11e-13]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 completed in 379.40 seconds, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 9618/9618 [06:30<00:00, 24.64batch/s, loss=8.88e-14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 completed in 390.39 seconds, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 9618/9618 [07:15<00:00, 22.11batch/s, loss=7.42e-14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 completed in 435.05 seconds, Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 9618/9618 [07:07<00:00, 22.48batch/s, loss=6.38e-14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 completed in 427.89 seconds, Loss: 0.0000\n",
      "Training complete in 3858.17 seconds\n",
      "TotalTraining:3859.370309829712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, genre_encoder, language_encoder = train_model(user_ids, track_ids, ratings, songs_data, merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOAD AND PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_encoders(n_users, n_items, n_factors, n_genres, n_languages):\n",
    "    model = NCFWithDemographics(n_users, n_items, n_factors, n_genres, n_languages)\n",
    "    model.load_state_dict(torch.load('Files\\ncf_model.pth'))\n",
    "    model.eval()\n",
    "    with open('Files\\genre_encoder.pkl', 'rb') as f:\n",
    "        genre_encoder = pickle.load(f)\n",
    "    with open('Files\\language_encoder.pkl', 'rb') as f:\n",
    "        language_encoder = pickle.load(f)\n",
    "    return model, genre_encoder, language_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_top_n(user_id, model, genre_id, language_id, age, gender, num_items, n=20):\n",
    "    item_vec = torch.arange(num_items)\n",
    "    user_vec = torch.full((num_items,), user_id)\n",
    "    genre_vec = torch.full((num_items,), genre_id)\n",
    "    language_vec = torch.full((num_items,), language_id)\n",
    "    age_vec = torch.full((num_items,), age)\n",
    "    gender_vec = torch.full((num_items,), gender)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(user_vec, item_vec, genre_vec, language_vec, age_vec, gender_vec).squeeze().numpy()\n",
    "    \n",
    "    top_n_indices = np.argsort(predictions)[-n:][::-1].copy()\n",
    "    return item_vec[top_n_indices].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_with_mood(user_id, user_top_20, db):\n",
    "    songs_collection = db['songs']\n",
    "    activity_collection = db['user_activity']\n",
    "\n",
    "    song_cursor = songs_collection.find(\n",
    "        {\"track_id\": {\"$in\": user_top_20.tolist()}},\n",
    "        {\"track_id\": 1, \"energy\": 1, \"valence\": 1}\n",
    "    )\n",
    "    top_20_songs = list(song_cursor)\n",
    "\n",
    "    track_ids = [song['track_id'] for song in top_20_songs]\n",
    "    features = np.array([[song['energy'], song['valence']] for song in top_20_songs])\n",
    "\n",
    "    pca = PCA(n_components=1)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "\n",
    "    user_mood = activity_collection.find_one(\n",
    "        {\"user_id\": user_id},\n",
    "        {\"mood_energy\": 1, \"mood_valence\": 1}\n",
    "    )\n",
    "\n",
    "\n",
    "    mood_energy = user_mood[\"mood_energy\"]\n",
    "    mood_valence = user_mood[\"mood_valence\"]\n",
    "    user_mood_point = pca.transform([[mood_energy, mood_valence]])\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=10)\n",
    "    nn.fit(reduced_features)\n",
    "    distances, indices = nn.kneighbors(user_mood_point)\n",
    "\n",
    "    final_10_tracks = [track_ids[i] for i in indices.flatten()]\n",
    "    return final_10_tracks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "199\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "n_users = 999\n",
    "num_items = 395386\n",
    "n_factors = 20\n",
    "n_genres=18\n",
    "n_languages = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chbha\\AppData\\Local\\Temp\\ipykernel_10836\\2619229215.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('ncf_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "model, genre_encoder, language_encoder = load_model_and_encoders(\n",
    "    n_users, num_items, n_factors, n_genres, n_languages\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    }
   ],
   "source": [
    "def retrieve_user_info(user_id):\n",
    "    user_data = pd.DataFrame(list(db[\"users\"].find({\"user_id\": user_id})))\n",
    "    activity_data = pd.DataFrame(list(db[\"user_activity\"].find({\"user_id\": user_id})))\n",
    "    if user_data.empty or activity_data.empty:\n",
    "        raise ValueError(f\"No data found for user_id: {user_id}\")\n",
    "    \n",
    "    age = user_data.iloc[0][\"user_age\"]\n",
    "    gender = user_data.iloc[0][\"user_gender\"]\n",
    "    preferred_language = activity_data.iloc[0][\"preferred_language\"]\n",
    "    preferred_genre = activity_data.iloc[0][\"preferred_genre\"]\n",
    "    \n",
    "    return age, gender, preferred_language, preferred_genre\n",
    "\n",
    "user_id = 2\n",
    "age, gender, preferred_language, preferred_genre = retrieve_user_info(user_id)\n",
    "\n",
    "genre_id = genre_encoder.transform([preferred_genre])[0]\n",
    "language_id = language_encoder.transform([preferred_language])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final 10 Recommended Songs for User 2 : [36083, 154381, 154382, 165112, 154340, 108432, 154365, 36077, 36074, 154383]\n"
     ]
    }
   ],
   "source": [
    "top_20_songs_per_user = recommend_top_n(user_id, model, genre_id, language_id, age, gender, num_items)\n",
    "final_10_songs = filter_with_mood(user_id, top_20_songs_per_user, db)\n",
    "print(\"Final 10 Recommended Songs for User\", user_id, \":\", final_10_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RETRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "client = MongoClient('MONGODB-URL')\n",
    "db = client['BUFFER-DATABASE-NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_new_data():\n",
    "    ratings_data = pd.DataFrame(list(db[\"buffer_ratings\"].find()))\n",
    "    songs_data = pd.DataFrame(list(db[\"buffer_songs\"].find()))\n",
    "    activity_data = pd.DataFrame(list(db[\"buffer_user_activity\"].find()))\n",
    "    user_data = pd.DataFrame(list(db[\"buffer_users\"].find()))\n",
    "\n",
    "    user_song_ratings = pd.pivot_table(ratings_data, values='rating', index='user_id', columns='track_id').fillna(0)\n",
    "\n",
    "    user_ids, track_ids = np.nonzero(user_song_ratings)\n",
    "    ratings = [user_song_ratings.iloc[user, track] for user, track in zip(user_ids, track_ids)]\n",
    "    merged_data = ratings_data.merge(activity_data, on=\"user_id\", how=\"left\").merge(user_data, on=\"user_id\", how=\"left\")\n",
    "    \n",
    "    return user_ids, track_ids, np.array(ratings), songs_data, merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RatingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, user_ids, track_ids, ratings, genres, languages, ages, genders):\n",
    "        self.user_ids = user_ids\n",
    "        self.track_ids = track_ids\n",
    "        self.ratings = ratings\n",
    "        self.genres = genres\n",
    "        self.languages = languages\n",
    "        self.ages = ages\n",
    "        self.genders = genders\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.user_ids[idx],\n",
    "            self.track_ids[idx],\n",
    "            self.ratings[idx],\n",
    "            self.genres[idx],\n",
    "            self.languages[idx],\n",
    "            self.ages[idx],\n",
    "            self.genders[idx]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(model, new_user_ids, new_track_ids, new_ratings, new_songs_data, new_merged_data):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.output.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    if new_user_ids:\n",
    "        for new_user_id in new_user_ids:\n",
    "            model.user_embeddings[new_user_id] = torch.randn(1, model.user_embedding_dim)\n",
    "\n",
    "    new_train_dataset = RatingDataset(\n",
    "        new_user_ids, new_track_ids, new_ratings,\n",
    "        new_merged_data.get('preferred_genre', []),\n",
    "        new_merged_data.get('preferred_language', []),\n",
    "        new_merged_data.get('user_age', []),\n",
    "        new_merged_data.get('user_gender', [])\n",
    "    )\n",
    "    new_train_loader = DataLoader(new_train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    for user_id, item_id, rating, genre_id, language_id, age, gender in new_train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(user_id, item_id, genre_id, language_id, age, gender)\n",
    "        loss = criterion(prediction.squeeze(), rating)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if new_songs_data:\n",
    "        for song_data in new_songs_data:\n",
    "            song_id = song_data['track_id']\n",
    "            model.song_embeddings[song_id] = torch.randn(1, model.song_embedding_dim)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path):\n",
    "    torch.save(model.state_dict(), file_path)\n",
    "\n",
    "def load_model(model, file_path):\n",
    "    model.load_state_dict(torch.load(file_path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationModel(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors, n_genres, n_languages):\n",
    "        super(RecommendationModel, self).__init__()\n",
    "        self.user_embedding_dim = n_factors\n",
    "        self.song_embedding_dim = n_factors\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(n_users, self.user_embedding_dim)\n",
    "        self.song_embeddings = nn.Embedding(n_items, self.song_embedding_dim)\n",
    "        \n",
    "        self.output = nn.Linear(self.user_embedding_dim + self.song_embedding_dim + n_genres + n_languages, 1)\n",
    "\n",
    "    def forward(self, user_id, item_id, genre_id, language_id, age, gender):\n",
    "        user_embed = self.user_embeddings(user_id)\n",
    "        song_embed = self.song_embeddings(item_id)\n",
    "        \n",
    "        features = torch.cat([user_embed, song_embed, genre_id, language_id, age, gender], dim=1)\n",
    "        \n",
    "        return self.output(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_user_ids, new_track_ids, new_ratings, new_songs_data, new_merged_data = retrieve_all_new_data()\n",
    "\n",
    "n_users = len(new_merged_data['user_id'].unique())\n",
    "n_items = len(new_songs_data['track_id'].unique())\n",
    "n_factors = 20\n",
    "n_genres = len(new_merged_data['preferred_genre'].unique())\n",
    "n_languages = len(new_merged_data['preferred_language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecommendationModel(n_users, n_items, n_factors, n_genres, n_languages)\n",
    "model = load_model(model, 'Files\\ncf_model.pth')\n",
    "\n",
    "model = fine_tune_model(model, new_user_ids, new_track_ids, new_ratings, new_songs_data, new_merged_data)\n",
    "save_model(model, 'Files\\ncf_model.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
